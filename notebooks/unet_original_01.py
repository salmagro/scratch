# -*- coding: utf-8 -*-
"""UNET_original_01

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bMAB985T2vZOC7ngElFDliThxuODnNcx

# Visualizing patches.
Creating 500 x 500 x channel images.
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
from torchvision import transforms
from torchvision.utils import save_image
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
# %matplotlib inline

tf_2_tensor = transforms.ToTensor()
tf_2_PIL = transforms.ToPILImage()

img_t = tf_2_tensor(Image.open('drive/MyDrive/ETH/train/images/austin10.tif'))
gt_t = tf_2_tensor(Image.open('drive/MyDrive/ETH/train/gt/austin10.tif'))

print('Original shape image = ', img_t.shape)
print('Original shape gt = ', gt_t.shape)

#torch.Tensor.unfold(dimension, size, step)
#slices the images into 500*500 size patches

kh, kw = 500, 500 # kernel size
dh, dw = 500, 500 # stride dize

img_channels = 3
gt_channels = 1

patches = img_t.data.unfold(0, img_channels, img_channels).unfold(1, kh, dh).unfold(2, kw, dw)

patches_gt = gt_t.data.unfold(0, gt_channels, gt_channels).unfold(1, kh, dh).unfold(2, kw, dw)

"""
Iterate the patches over:

    patches[0][rows][columns] 

"""

print('Patch shape image =',patches[0][0][0].shape)
print('Patch shape gt =',patches_gt[0][0][0].shape)

number_images = 10
def visualize(patches):
    """Imshow for Tensor."""    
    fig = plt.figure(figsize=(number_images, number_images))
    for i in range(number_images):
        for j in range(number_images):
            inp = tf_2_PIL(patches[0][i][j])
            inp = np.array(inp)
            ax = fig.add_subplot(number_images, number_images, ((i*number_images)+j)+1, xticks=[], yticks=[])
            plt.imshow(inp)

visualize(patches)        
visualize(patches_gt)

"""# Storing patches
Different foders will be provided to speed up the training.
"""

# Creating directories in local disk
# !ls
!mkdir train_patch_01 train_patch_02 train_patch_03
!mkdir train_patch_01/images train_patch_01/gt
!mkdir train_patch_02/images train_patch_02/gt
!mkdir train_patch_03/images train_patch_03/gt

# Reading file names
import os 

def create_patches(source_dir, complete_save_dir, batch_source, plotting=False, verbose=False):
  """
  args:
        source_dir = Path for reading original images
        complete_save_dir = Path for saving patches
        plotting = Flag to plot intermiadte results
        verbose = Flag for printing shapes
  """
  complete_name_images = os.listdir(source_dir)
  if batch_source == 1:
    save_dir = complete_save_dir[0]
    name_images = complete_name_images[0:60]
  elif batch_source == 2:
    save_dir = complete_save_dir[1]
    name_images = complete_name_images[60:120]
  elif batch_source == 3:
    save_dir = complete_save_dir[2]
    name_images = complete_name_images[120:180]

  
  iteration = 0
  for i in name_images:
    image_t = tf_2_tensor(Image.open(source_dir + '/' + i))
    print("image_t.shape =", image_t.shape) if verbose else None
    
    name_gt = (source_dir +'/%s'%i).replace("images", "gt")
    gt_t = tf_2_tensor(Image.open(name_gt))
    print("gt_t.shape =", gt_t.shape) if verbose else None

    # Creating patches
    patches = image_t.data.unfold(0, img_channels, img_channels).unfold(1, kh, dh).unfold(2, kw, dw)
    patches_gt = gt_t.data.unfold(0, gt_channels, gt_channels).unfold(1, kh, dh).unfold(2, kw, dw)
    
    if plotting:
      visualize(patches)
      visualize(patches_gt)
    
    # todo: Not save it gt are empty
    # itering over patches to save patches
    for j in range(number_images):
      for k in range(number_images):
        name_save = (save_dir +"/images/%s" % i).replace(".tif", '_' + str(j) + '_' + str(k) + '.tif')
        save_image(patches[0][j][k], name_save)
        print(patches[0][j][k].shape) if verbose else None
        name_gt_save = (name_save).replace("images", "gt")
        print(patches_gt[0][j][k].shape) if verbose else None
        save_image(patches_gt[0][j][k], name_gt_save)
    print('file saved =', i)

    iteration += 1
    print("itearation =", iteration)
    # if iteration == 2:
    #   break


"""
Due the limitation of memory, patches should be created in subset at a time, 
eg. 1, 2 or 3
Each batch will contain 6000 images.
"""

path_dir = 'drive/MyDrive/ETH/train/images'
# save_dir = 'drive/MyDrive/ETH/train_patch/images'

complete_save_dir = ['train_patch_01','train_patch_02','train_patch_03']

create_patches(path_dir, complete_save_dir, 1)

!ls train_patch_01/gt
# !rm -rf train_patch_01/*.tif

"""# Common commands"""

# Erasing
# !rm -rf drive/MyDrive/ETH/train_patch/images/*
# !rm -rf drive/MyDrive/ETH/train_patch/gt/*

# !ls drive/MyDrive/ETH/train/gt

!ls drive/MyDrive/ETH/train_patch/gt 

# Counting the number of files
# !ls drive/MyDrive/ETH/train_patch/images | wc -l
# !ls drive/MyDrive/ETH/train_patch/gt | wc -l

# !ls drive/MyDrive/ETH/train_patch/images | wc -l
!ls train_patch_01/gt | wc -l

"""# Test opening patches"""

# path_test = 'drive/MyDrive/ETH/train/images/tyrol-w2.tif'
path_test = 'drive/MyDrive/ETH/train/images/tyrol-w2.tif'
plt.figure()
image = tf_2_tensor(Image.open(path_test))
print(image.shape)
inp = np.array(tf_2_PIL(image))
plt.imshow(inp)
print("image",inp.shape)
plt.figure()
gt = tf_2_tensor(Image.open(path_test.replace('images','gt')))
print(gt.shape)
inp = np.array(tf_2_PIL(gt))
plt.imshow(inp)
print("gt",inp.shape)

# path_test = 'drive/MyDrive/ETH/train_patch/images/tyrol-w2_0_0.tif'
path_test = 'train_patch_01/images/tyrol-w2_0_0.tif'
plt.figure()
image = tf_2_tensor(Image.open(path_test))
print(image.shape)
inp = np.array(tf_2_PIL(image))
plt.imshow(inp)
print("image",inp.shape)


plt.figure()
gt = tf_2_tensor(Image.open(path_test.replace('images','gt')))
print(gt.shape)
inp = np.array(tf_2_PIL(gt[:,:,:]))
plt.imshow(inp)
print("gt",inp.shape)

"""# U-NET implementation"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.

# Commented out IPython magic to ensure Python compatibility.
from pathlib import Path
from torch.utils.data import Dataset, DataLoader, sampler
from PIL import Image
import torch
import matplotlib.pyplot as plt
import time

# For plotting patches
from torchvision import transforms
from PIL import Image
import numpy as np
# %matplotlib inline

# For tensorboard
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter()

tf_2_tensor = transforms.ToTensor()
tf_2_PIL = transforms.ToPILImage()

class ImageDataset(Dataset):
    # def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):
    def __init__(self, images_dir, gt_dir, pytorch=True):
        super().__init__()
        
        # Loop through the files in red folder and combine, into a dictionary, the other bands
        # self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]
        self.files = [self.combine_files(f, gt_dir) for f in images_dir.iterdir() if not f.is_dir()]
        # self.files = self.combine_files(images_dir, gt_dir)
        self.pytorch = pytorch
        
    # def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):
    def combine_files(self, images_file: Path, gt_dir):
        
        files = {'images': images_file, 
                 'gt': gt_dir/images_file.name.replace('images', 'gt')}
      
        return files
                                       
    def __len__(self):
        
        return len(self.files)
     
    def open_as_array(self, idx, invert=False):

        raw_rgb = np.array(Image.open(self.files[idx]['images']).resize((256,256)))

        if invert:
            raw_rgb = raw_rgb.transpose((2,0,1))
        
        # normalize
        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)  

    def open_mask(self, idx, add_dims=False):
        
        raw_mask = np.array(Image.open(self.files[idx]['gt']).getchannel(0).resize((256,256)))
        
        # plt.figure()
        # image = tf_2_tensor(Image.open(self.files[idx]['gt']))
        # inp = np.array(tf_2_PIL(image))
        # plt.imshow(inp)
        # print("inp",inp.shape)
        
        raw_mask = np.where(raw_mask==255, 1, 0)
        
        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask
    
    def __getitem__(self, idx):
        
        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch), dtype=torch.float32)
        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)

        return x, y
    
    def open_as_pil(self, idx):
        
        arr = 256*self.open_as_array(idx)
        
        return Image.fromarray(arr.astype(np.uint8), 'RGB')
    
    def __repr__(self):
        s = 'Dataset class with {} files'.format(self.__len__())

        return s

# train_path = Path('drive/MyDrive/ETH/train_patch/')
train_path = Path('train_patch_01/')

data = ImageDataset(train_path/'images', train_path/'gt')

# test_path = Path('drive/MyDrive/ETH/test/')
# test = ImageDataset(test_path/'images', 
#                     test_path/'gt')
print('len(data)=',len(data))
# print('len(test)=',len(test))

x_patches, y_patches = data[10]
x_patches.shape, y_patches.shape

fig, ax = plt.subplots(1,2, figsize=(10,9))
ax[0].imshow(data.open_as_array(100))
ax[1].imshow(data.open_mask(100))

# train_ds, valid_ds = torch.utils.data.random_split(data, (14400, 3600))
train_ds, valid_ds = torch.utils.data.random_split(data, (4800, 1200))

train_dl = DataLoader(train_ds, batch_size=12, shuffle=True)
valid_dl = DataLoader(valid_ds, batch_size=12, shuffle=True)

xb, yb = next(iter(train_dl))
xb.shape, yb.shape

"""# Model"""

from torch import nn
class UNET(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()

        self.conv1 = self.contract_block(in_channels, 32, 7, 3)
        self.conv2 = self.contract_block(32, 64, 3, 1)
        self.conv3 = self.contract_block(64, 128, 3, 1)

        self.upconv3 = self.expand_block(128, 64, 3, 1)
        self.upconv2 = self.expand_block(64*2, 32, 3, 1)
        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)

    def __call__(self, x):

        # downsampling part
        conv1 = self.conv1(x)
        conv2 = self.conv2(conv1)
        conv3 = self.conv3(conv2)

        upconv3 = self.upconv3(conv3)

        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))
        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))

        return upconv1

    def contract_block(self, in_channels, out_channels, kernel_size, padding):

        contract = nn.Sequential(
            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),
            torch.nn.BatchNorm2d(out_channels),
            torch.nn.ReLU(),
            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),
            torch.nn.BatchNorm2d(out_channels),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
                                 )

        return contract

    def expand_block(self, in_channels, out_channels, kernel_size, padding):

        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),
                            torch.nn.BatchNorm2d(out_channels),
                            torch.nn.ReLU(),
                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),
                            torch.nn.BatchNorm2d(out_channels),
                            torch.nn.ReLU(),
                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) 
                            )
        return expand

unet = UNET(3,2)

# testing one pass
xb, yb = next(iter(train_dl))
xb.shape, yb.shape

pred = unet(xb)
pred.shape

from tqdm.notebook import trange, tqdm, tqdm_notebook
import time
from IPython.display import clear_output

def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):
    start = time.time()
    model.cuda()

    train_loss, valid_loss = [], []

    best_acc = 0.0

    for epoch in tqdm_notebook(range(epochs)):
        print('Epoch {}/{}'.format(epoch, epochs - 1))
        print('-' * 10)

        for phase in ['train', 'valid']:
            if phase == 'train':
                model.train(True)  # Set trainind mode = true
                dataloader = train_dl
            else:
                model.train(False)  # Set model to evaluate mode
                dataloader = valid_dl

            running_loss = 0.0
            running_acc = 0.0

            step = 0

            # iterate over data
            for x, y in dataloader:
                x = x.cuda()
                y = y.cuda()
                step += 1

                # forward pass
                if phase == 'train':
                    # zero the gradients
                    optimizer.zero_grad()
                    outputs = model(x)
                    loss = loss_fn(outputs, y)

                    # the backward pass frees the graph memory, so there is no 
                    # need for torch.no_grad in this training pass
                    loss.backward()
                    optimizer.step()
                    # scheduler.step()

                else:
                    with torch.no_grad():
                        outputs = model(x)
                        loss = loss_fn(outputs, y.long())

                # stats - whatever is the phase
                acc = acc_fn(outputs, y)

                running_acc  += acc*dataloader.batch_size
                running_loss += loss*dataloader.batch_size 

                if step % 100 == 0:
                    # clear_output(wait=True)
                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))
                    # print(torch.cuda.memory_summary())

            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_acc = running_acc / len(dataloader.dataset)

            clear_output(wait=True)
            print('Epoch {}/{}'.format(epoch, epochs - 1))
            print('-' * 10)
            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))
            print('-' * 10)
            
            # Log for tensorboard
            writer.add_scalar("Loss/train", epoch_loss, epoch_acc, epochs)

            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)

    time_elapsed = time.time() - start
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    
    # torch.save(model,'drive/MyDrive/ETH/')
    writer.flush()
    return train_loss, valid_loss, model    

def acc_metric(predb, yb):
    return (predb.argmax(dim=1) == yb.cuda()).float().mean()

loss_fn = nn.CrossEntropyLoss()
opt = torch.optim.Adam(unet.parameters(), lr=0.01)
train_loss, valid_loss, model = train(unet, train_dl, valid_dl, loss_fn, opt, acc_metric, epochs=50)
writer.close()

# model
# torch.save(model,'drive/MyDrive/ETH/model_2020-12-25.pt')
# torch.save(model,'drive/MyDrive/ETH/checkpoint_model_2020-12-25.ckpt')
torch.save(model.state_dict(),'drive/MyDrive/ETH/checkpoint_model_2020-12-25.ckpt')
# torch.save(model.state_dict(), PATH)

plt.figure(figsize=(10,8))
plt.plot(train_loss, label='Train loss')
plt.plot(valid_loss, label='Valid loss')
plt.legend()

"""# Prediction"""

def batch_to_img(xb, idx):
    img = np.array(xb[idx,0:3])
    return img.transpose((1,2,0))

def predb_to_mask(predb, idx):
    p = torch.functional.F.softmax(predb[idx], 0)
    return p.argmax(0).cpu()

xb, yb = next(iter(train_dl))

with torch.no_grad():
    predb = unet(xb.cuda())

predb.shape

bs = 12
fig, ax = plt.subplots(bs,3, figsize=(15,bs*5))
for i in range(bs):
    ax[i,0].imshow(batch_to_img(xb,i))
    ax[i,1].imshow(yb[i])
    ax[i,2].imshow(predb_to_mask(predb, i))

!tensorboard --logdir=runs

!mv runs/Dec25_13-16-07_ad5a0d255d52 drive/MyDrive/ETH/Dec25_13-16-07_ad5a0d255d52